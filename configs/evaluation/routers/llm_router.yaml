run_mode: compound

router:
  type: llm
  confidence_threshold: 0.7
  llm_config:
    type: "ollama"
    model_name: "phi"  # or phi:2.7b
    host: "http://localhost:11434"

small_llm:
  type: "ollama"
  model_name: "llama3.2:3b"
  host: "http://localhost:11434"

large_llm:
  type: "claude"
  model_name: "claude-3-haiku-20240307"
  api_key: ${oc.env:ANTHROPIC_API_KEY}

evaluation:
  output_dir: "results/llm_router"
  num_samples: 500
  seed: 42
  output_file: "results/llm_router/llm_router_results.json"